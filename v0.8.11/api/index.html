<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · KernelFunctions</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">KernelFunctions</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../userguide/">User Guide</a></li><li><a class="tocitem" href="../example/">Examples</a></li><li><a class="tocitem" href="../kernels/">Kernel Functions</a></li><li><a class="tocitem" href="../transform/">Input Transforms</a></li><li><a class="tocitem" href="../metrics/">Metrics</a></li><li><a class="tocitem" href="../theory/">Theory</a></li><li><a class="tocitem" href="../create_kernel/">Custom Kernels</a></li><li class="is-active"><a class="tocitem" href>API</a><ul class="internal"><li><a class="tocitem" href="#Module"><span>Module</span></a></li><li><a class="tocitem" href="#Base-Kernels-API"><span>Base Kernels API</span></a></li><li><a class="tocitem" href="#Composite-Kernels"><span>Composite Kernels</span></a></li><li><a class="tocitem" href="#Transforms"><span>Transforms</span></a></li><li><a class="tocitem" href="#Functions"><span>Functions</span></a></li><li><a class="tocitem" href="#Utilities"><span>Utilities</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/master/docs/src/api.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="API-Library"><a class="docs-heading-anchor" href="#API-Library">API Library</a><a id="API-Library-1"></a><a class="docs-heading-anchor-permalink" href="#API-Library" title="Permalink"></a></h1><hr/><ul><li><a href="#API-Library">API Library</a></li><ul><li><a href="#Module">Module</a></li><li><a href="#Base-Kernels-API">Base Kernels API</a></li><li><a href="#Composite-Kernels">Composite Kernels</a></li><li><a href="#Transforms">Transforms</a></li><li><a href="#Functions">Functions</a></li><li><a href="#Utilities">Utilities</a></li><li><a href="#Index">Index</a></li></ul></ul><h2 id="Module"><a class="docs-heading-anchor" href="#Module">Module</a><a id="Module-1"></a><a class="docs-heading-anchor-permalink" href="#Module" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.KernelFunctions" href="#KernelFunctions.KernelFunctions"><code>KernelFunctions.KernelFunctions</code></a> — <span class="docstring-category">Module</span></header><section><div><p>KernelFunctions. <a href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl">Github</a> <a href="https://juliagaussianprocesses.github.io/KernelFunctions.jl/stable/">Documentation</a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/KernelFunctions.jl#L1-L4">source</a></section></article><h2 id="Base-Kernels-API"><a class="docs-heading-anchor" href="#Base-Kernels-API">Base Kernels API</a><a id="Base-Kernels-API-1"></a><a class="docs-heading-anchor-permalink" href="#Base-Kernels-API" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ConstantKernel" href="#KernelFunctions.ConstantKernel"><code>KernelFunctions.ConstantKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ConstantKernel(; c=1.0)</code></pre><p>Kernel function always returning a constant value <code>c</code></p><pre><code class="language-none">    κ(x,y) = c</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/constant.jl#L42-L49">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.WhiteKernel" href="#KernelFunctions.WhiteKernel"><code>KernelFunctions.WhiteKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">WhiteKernel()</code></pre><pre><code class="language-none">    κ(x,y) = δ(x,y)</code></pre><p>Kernel function working as an equivalent to add white noise. Can also be called via <code>EyeKernel()</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/constant.jl#L18-L25">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.EyeKernel" href="#KernelFunctions.EyeKernel"><code>KernelFunctions.EyeKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">EyeKernel()</code></pre><p>See <a href="#KernelFunctions.WhiteKernel"><code>WhiteKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/constant.jl#L28-L32">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ZeroKernel" href="#KernelFunctions.ZeroKernel"><code>KernelFunctions.ZeroKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ZeroKernel()</code></pre><p>Create a kernel that always returns zero</p><pre><code class="language-none">    κ(x,y) = 0.0</code></pre><p>The output type depends on <code>x</code> and <code>y</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/constant.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.CosineKernel" href="#KernelFunctions.CosineKernel"><code>KernelFunctions.CosineKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">CosineKernel()</code></pre><p>The cosine kernel is a stationary kernel for a sinusoidal given by</p><pre><code class="language-none">    κ(x,y) = cos( π * (x-y) )</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/cosine.jl#L1-L8">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.SqExponentialKernel" href="#KernelFunctions.SqExponentialKernel"><code>KernelFunctions.SqExponentialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">SqExponentialKernel()</code></pre><p>The squared exponential kernel is a Mercer kernel given by the formula:</p><pre><code class="language-none">    κ(x, y) = exp(-‖x - y‖² / 2)</code></pre><p>Can also be called via <code>RBFKernel</code>, <code>GaussianKernel</code> or <code>SEKernel</code>. See <a href="#KernelFunctions.GammaExponentialKernel"><code>GammaExponentialKernel</code></a> for a generalization.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/exponential.jl#L1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ExponentialKernel" href="#KernelFunctions.ExponentialKernel"><code>KernelFunctions.ExponentialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ExponentialKernel()</code></pre><p>The exponential kernel is a Mercer kernel given by the formula:</p><pre><code class="language-none">    κ(x,y) = exp(-‖x-y‖)</code></pre><p>Can also be called via <code>LaplacianKernel</code> or <code>Matern12Kernel</code>. See <a href="#KernelFunctions.GammaExponentialKernel"><code>GammaExponentialKernel</code></a> for a generalization.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/exponential.jl#L45-L54">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.GammaExponentialKernel" href="#KernelFunctions.GammaExponentialKernel"><code>KernelFunctions.GammaExponentialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GammaExponentialKernel(; γ = 2.0)</code></pre><p>The γ-exponential kernel [1] is an isotropic Mercer kernel given by the formula:</p><pre><code class="language-none">    κ(x,y) = exp(-‖x-y‖^γ)</code></pre><p>Where <code>γ &gt; 0</code>, (the keyword <code>γ</code> can be replaced by <code>gamma</code>) For <code>γ = 2</code>, see <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a>; for <code>γ = 1</code>, see <a href="#KernelFunctions.ExponentialKernel"><code>ExponentialKernel</code></a>.</p><p>[1] - Gaussian Processes for Machine Learning, Carl Edward Rasmussen and Christopher K. I.     Williams, MIT Press, 2006.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/exponential.jl#L82-L94">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ExponentiatedKernel" href="#KernelFunctions.ExponentiatedKernel"><code>KernelFunctions.ExponentiatedKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ExponentiatedKernel()</code></pre><p>The exponentiated kernel is a Mercer kernel given by:</p><pre><code class="language-none">    κ(x,y) = exp(xᵀy)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/exponentiated.jl#L1-L8">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.FBMKernel" href="#KernelFunctions.FBMKernel"><code>KernelFunctions.FBMKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FBMKernel(; h::Real=0.5)</code></pre><p>Fractional Brownian motion kernel with Hurst index <code>h</code> from (0,1) given by</p><pre><code class="language-none">    κ(x,y) =  ( |x|²ʰ + |y|²ʰ - |x-y|²ʰ ) / 2</code></pre><p>For <code>h=1/2</code>, this is the Wiener Kernel, for <code>h&gt;1/2</code>, the increments are positively correlated and for <code>h&lt;1/2</code> the increments are negatively correlated.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/fbm.jl#L1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.GaborKernel" href="#KernelFunctions.GaborKernel"><code>KernelFunctions.GaborKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GaborKernel(; ell::Real=1.0, p::Real=1.0)</code></pre><p>Gabor kernel with lengthscale <code>ell</code> and period <code>p</code>. Given by</p><p class="math-container">\[    κ(x,y) =  h(x-z), h(t) = exp(-sum(t.^2./(ell.^2)))*cos(pi*sum(t./p))\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/gabor.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.MaternKernel" href="#KernelFunctions.MaternKernel"><code>KernelFunctions.MaternKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MaternKernel(; ν = 1.0)</code></pre><p>The matern kernel is a Mercer kernel given by the formula:</p><pre><code class="language-none">    κ(x,y) = 2^{1-ν}/Γ(ν)*(√(2ν)‖x-y‖)^ν K_ν(√(2ν)‖x-y‖)</code></pre><p>For <code>ν=n+1/2, n=0,1,2,...</code> it can be simplified and you should instead use  <a href="#KernelFunctions.ExponentialKernel"><code>ExponentialKernel</code></a> for <code>n=0</code>, <a href="#KernelFunctions.Matern32Kernel"><code>Matern32Kernel</code></a>, for <code>n=1</code>,  <a href="#KernelFunctions.Matern52Kernel"><code>Matern52Kernel</code></a> for <code>n=2</code> and <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a> for <code>n=∞</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/matern.jl#L1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.Matern32Kernel" href="#KernelFunctions.Matern32Kernel"><code>KernelFunctions.Matern32Kernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Matern32Kernel()</code></pre><p>The matern 3/2 kernel is a Mercer kernel given by the formula:</p><pre><code class="language-none">    κ(x,y) = (1+√(3)‖x-y‖)exp(-√(3)‖x-y‖)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/matern.jl#L38-L45">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.Matern52Kernel" href="#KernelFunctions.Matern52Kernel"><code>KernelFunctions.Matern52Kernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Matern52Kernel()</code></pre><p>The matern 5/2 kernel is a Mercer kernel given by the formula:</p><pre><code class="language-none">    κ(x,y) = (1+√(5)‖x-y‖ + 5/3‖x-y‖^2)exp(-√(5)‖x-y‖)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/matern.jl#L54-L61">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.NeuralNetworkKernel" href="#KernelFunctions.NeuralNetworkKernel"><code>KernelFunctions.NeuralNetworkKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">NeuralNetworkKernel()</code></pre><p>Neural network kernel function.</p><p class="math-container">\[    κ(x, y) =  asin(x&#39; * y / sqrt[(1 + x&#39; * x) * (1 + y&#39; * y)])\]</p><p><strong>Significance</strong></p><p>Neal (1996) pursued the limits of large models, and showed that a Bayesian neural network becomes a Gaussian process with a <strong>neural network kernel</strong> as the number of units approaches infinity. Here, we give the neural network kernel for single hidden layer Bayesian neural network with erf (Error Function) as activation function.</p><p><strong>References:</strong></p><ul><li><a href="http://www.gaussianprocess.org/gpml/chapters/RW4.pdf">GPML Pg 105</a></li><li><a href="https://www.cs.toronto.edu/~radford/bnn.book.html">Neal(1996)</a></li><li><a href="http://www.cs.cmu.edu/~andrewgw/andrewgwthesis.pdf">Andrew Gordon&#39;s Thesis Pg 45</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/nn.jl#L1-L19">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.LinearKernel" href="#KernelFunctions.LinearKernel"><code>KernelFunctions.LinearKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LinearKernel(; c = 0.0)</code></pre><p>The linear kernel is a Mercer kernel given by</p><pre><code class="language-none">    κ(x,y) = xᵀy + c</code></pre><p>Where <code>c</code> is a real number</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/polynomial.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.PolynomialKernel" href="#KernelFunctions.PolynomialKernel"><code>KernelFunctions.PolynomialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">PolynomialKernel(; d = 2.0, c = 0.0)</code></pre><p>The polynomial kernel is a Mercer kernel given by</p><pre><code class="language-none">    κ(x,y) = (xᵀy + c)^d</code></pre><p>Where <code>c</code> is a real number, and <code>d</code> is a shape parameter bigger than 1. For <code>d = 1</code> see <a href="#KernelFunctions.LinearKernel"><code>LinearKernel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/polynomial.jl#L25-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.PiecewisePolynomialKernel" href="#KernelFunctions.PiecewisePolynomialKernel"><code>KernelFunctions.PiecewisePolynomialKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">PiecewisePolynomialKernel{V}(maha::AbstractMatrix)</code></pre><p>Piecewise Polynomial covariance function with compact support, V = 0,1,2,3. The kernel functions are 2V times continuously differentiable and the corresponding processes are hence V times mean-square differentiable. The kernel function is:</p><p class="math-container">\[    κ(x, y) = max(1 - r, 0)^(j + V) * f(r, j) with j = floor(D / 2) + V + 1\]</p><p>where <code>r</code> is the Mahalanobis distance mahalanobis(x,y) with <code>maha</code> as the metric.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/piecewisepolynomial.jl#L1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.MahalanobisKernel" href="#KernelFunctions.MahalanobisKernel"><code>KernelFunctions.MahalanobisKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MahalanobisKernel(P::AbstractMatrix)</code></pre><p>Mahalanobis distance-based kernel given by</p><p class="math-container">\[    κ(x,y) =  exp(-r^2), r^2 = maha(x,P,y) = (x-y)&#39;* P *(x-y)\]</p><p>where the matrix P is the metric.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/maha.jl#L1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.RationalQuadraticKernel" href="#KernelFunctions.RationalQuadraticKernel"><code>KernelFunctions.RationalQuadraticKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">RationalQuadraticKernel(; α=2.0)</code></pre><p>The rational-quadratic kernel is a Mercer kernel given by the formula:</p><pre><code class="language-none">    κ(x, y) = (1 + ||x − y||² / (2α))^(-α)</code></pre><p>where <code>α</code> is a shape parameter of the Euclidean distance. Check <a href="#KernelFunctions.GammaRationalQuadraticKernel"><code>GammaRationalQuadraticKernel</code></a> for a generalization.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/rationalquad.jl#L1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.GammaRationalQuadraticKernel" href="#KernelFunctions.GammaRationalQuadraticKernel"><code>KernelFunctions.GammaRationalQuadraticKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>GammaRationalQuadraticKernel([α=2.0 [, γ=2.0]])</code></p><p>The Gamma-rational-quadratic kernel is an isotropic Mercer kernel given by the formula:</p><pre><code class="language-none">    κ(x, y) = (1 + ||x−y||^γ / α)^(-α)</code></pre><p>where <code>α</code> is a shape parameter of the Euclidean distance and <code>γ</code> is another shape parameter.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/rationalquad.jl#L31-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.spectral_mixture_kernel" href="#KernelFunctions.spectral_mixture_kernel"><code>KernelFunctions.spectral_mixture_kernel</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">spectral_mixture_kernel(
<!-- NAVBAR START -->
<style>
    html {
        scroll-padding-top: calc(55px + 1rem);
    }

    /* Documenter css tweaks */
    .docs-sidebar {
        margin-top: 3.75rem;
    }

    #documenter {
        margin-top: 3.75rem;
    }

    .docs-version-selector {
        margin-bottom: 60px !important;
    }

    @media screen and (max-width: 1056px) {
        .docs-version-selector {
            margin-bottom: 60px !important;
        }

        .docs-sidebar {
            margin-top: 0 !important;
        }
    }
    /* Documenter css tweaks ends here */

    :root {
        --heading-color: white;
        --item-color: rgb(165, 165, 165);
        --primary-bg: #073c44;
        --hover-color: #8faad2;
    }

    .ext-navigation {
        position: fixed;
        height: 3.75rem;
        top: 0;
        width: 100%;
        background-color: var(--primary-bg);
        z-index: 1000;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        display: flex;
        align-items: center;
        padding: 0 1.0625rem;
        transition: transform 0.3s;
    }

    .ext-navbar-logo {
        margin-left: 0.625rem;
    }

    .ext-nav-links {
        display: flex;
        align-items: center;
        list-style-type: none;
        margin: 0;
        padding: 0;
        flex-grow: 1;
    }

    .ext-nav-links li {
        margin-left: 1rem !important;
    }

    .ext-nav-link {
        color: white !important;
        text-decoration: none;
        font-size: 1.0625rem !important;
        transition: color 0.2s ease;
        cursor: pointer;
    }

    .ext-nav-link:hover,
    .ext-navbar-item-single a:hover {
        color: var(--hover-color) !important;
    }

    .ext-navbar-item-single a {
        color: #fff !important;
    }

    .ext-menu-toggle {
        display: none;
        font-size: 1.5rem;
        color: white;
        cursor: pointer;
    }

    .ext-dropdown {
        display: none;
        grid-template-columns: 1fr 1fr 1fr 1fr;
        grid-template-rows: auto auto auto;
        padding: 1.875rem;
        position: absolute;
        width: 100%;
        left: 0;
        background-color: #083c44;
        line-height: 1.875rem;
        opacity: 0;
        transition: opacity 0.3s ease-in-out, transform 0.3s ease-in-out;
        transform: translateY(-0.625rem);
    }

    #library-handler::after {
        content: "▼";
        font-size: 0.6875rem;
        margin-left: 0.3125rem;
        transition: transform 0.3s ease-in-out;
    }

    #library-handler.open::after {
        content: "▲";
    }

    .ext-dropdown.show {
        display: grid;
        opacity: 1;
        transform: translateY(0);
    }

    .ext-dropdown ul {
        height: auto;
        width: 12.5rem;
        margin-bottom: 1.25rem;
    }

    .ext-dropdown ul li {
        text-align: left;
    }

    .navbar-sub-item {
        list-style: none;
    }

    .ext-dropdown ul a li {
        color: var(--item-color);
        width: 15.625rem;
        border-radius: 3px;
        padding: 0.125rem 0.625rem;
        transition: background-color 0.2s ease;
    }

    .ext-dropdown ul a li:hover {
        background-color: rgba(107, 107, 107, 0.5);
    }

    .ext-dropdown-item-heading {
        color: var(--heading-color);
        text-align: center;
    }

    /* Responsive styling */
    @media (max-width: 966px) {
        .ext-dropdown {
            grid-template-columns: 1fr 1fr 1fr;
        }
    }

    @media (max-width: 768px) {
        .ext-nav-links {
            display: none;
            flex-direction: column;
            width: 100%;
            background-color: var(--primary-bg);
            position: absolute;
            top: 3.75rem;
            left: 0;
            padding: 0.625rem 0;
            height: auto;
            overflow-y: auto;
            scrollbar-width: thin;
            scrollbar-color: rgb(141, 141, 141) grey;
        }

        .ext-nav-links.show {
            display: flex;
        }

        .ext-nav-links li {
            margin: 0.625rem 0;
            text-align: center;
        }

        .ext-menu-toggle {
            display: block;
            margin-left: auto;
        }

        .ext-navigation.hide {
            transform: translateY(-3.75rem);
        }

        .ext-dropdown {
            place-content: center;
            text-align: center;
            grid-template-columns: 1fr;
            line-height: 1.25rem;
            padding: 0.625rem;
        }

        .ext-dropdown ul {
            width: 100%;
            text-align: center;
            margin-bottom: 0.3125rem;
        }

        .ext-dropdown ul li {
            text-align: center;
        }

        .ext-dropdown ul a li {
            width: 100%;
        }

        .ext-dropdown ul a li:hover {
            background-color: var(--primary-bg);
            color: #fff;
        }

        /* Modified scroll bar */
        .ext-nav-links::-webkit-scrollbar {
            width: 5px;
        }

        .ext-nav-links::-webkit-scrollbar-track {
            box-shadow: inset 0 0 5px grey;
        }

        .ext-nav-links::-webkit-scrollbar-thumb {
            background: rgb(141, 141, 141);
            border-radius: 3px;
        }

        .ext-nav-links::-webkit-scrollbar-thumb:hover {
            background: #9b9b9b;
        }
    }
    @media only screen and (max-width: 768px) {
        .turing-logo {
            display: none !important;
        }
    }
    @media only screen and (min-width: 768px) {
        .turing-collab {
            display: none !important;
        }
    }
</style>
<nav class="ext-navigation">
    <a href="https://github.com/JuliaGaussianProcesses">
        <img src="https://avatars.githubusercontent.com/u/57909728?s=200&v=4" alt="JuliaGP Logo" class="ext-navbar-logo" height="24px" width="40px">
    </a>
    <a style="color: white !important; font-size: 21.25px !important; margin-left: 10px;" href="https://github.com/JuliaGaussianProcesses">JuliaGP</a>
    <ul class="ext-nav-links">
        <li>
            <a class="ext-nav-link" href="https://juliagaussianprocesses.github.io/AbstractGPs.jl/">AbstractGPs</a>
        </li>
        <li>
            <a class="ext-nav-link" href="https://juliagaussianprocesses.github.io/KernelFunctions.jl/">KernelFunctions</a>
        </li>
        <li>
            <a class="ext-nav-link" href="https://juliagaussianprocesses.github.io/GPLikelihoods.jl/">GPLikelihoods</a>
        </li>
        <li>
            <a class="ext-nav-link" href="https://juliagaussianprocesses.github.io/ApproximateGPs.jl/">ApproximateGPs</a>
        </li>
        <li>
            <a class="ext-nav-link turing-collab" href="https://turinglang.org">Co-developed with Turing.jl</a>
        </li>
        <!-- Add a Dropdown with these classes in case it's required so that the current CSS works fine -->
        <!-- <li>
            <p class="ext-nav-link" id="library-handler">Libraries</p>
            <div class="ext-dropdown" id="ext-dropdown-items">
                <ul>
                    <li class="ext-dropdown-item-heading">Modellinglanguages</li>
                    <a href="https://turinglang.org/DynamicPPL.jl/">
                        <li>DynamicPPL</li>
                    </a>
                    <a href="https://turinglang.org/JuliaBUGS.jl/">
                        <li>JuliaBUGS</li>
                    </a>
                    <a href="https://turinglang.org/TuringGLM.jl/">
                        <li>TurineGLM</li>
                    </a>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading">MCMC</li>
                    <a href="https://turinglang.org/AdvancedHMC.jl/">
                        <li>AdvancedHMC</li>
                    </a>
                    <a href="https://turinglang.org/AbstractMCMC.jl/">
                        <li>AbstractMCMC</li>
                    </a>
                    <a href="https://github.com/theogf/ThermodynamicIntegration.jl">
                        <li>ThermodynamicIntegration</li>
                    </a>
                    <a href="https://turinglang.org/AdvancedPS.jl/">
                        <li>AdvancedPS</li>
                    </a>
                    <a href="https://turinglang.org/EllipticalSliceSampling.jl/">
                        <li>EllipticalSliceSampling</li>
                    </a>
                    <a href="https://turinglang.org/NestedSamplers.jl/">
                        <li>NestedSamplers</li>
                    </a>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading">Diagnostics</li>
                    <a href="https://turinglang.org/MCMCChains.jl/">
                        <li>MCMCChains</li>
                    </a>
                    <a href="https://turinglang.org/MCMCDiagnosticTools.jl/">
                        <li>MCMCDiagnosticTools</li>
                    </a>
                    <a href="https://turinglang.org/ParetoSmooth.jl/">
                        <li>ParetoSmooth</li>
                    </a>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading">Gaussion Processes</li>
                    <a href="https://juliagaussianprocesses.github.io/AbstractGPs.jl/">
                        <li>AbstractGPs</li>
                    </a>
                    <a href="https://juliagaussianprocesses.github.io/KernelFunctions.jl/">
                        <li>KernelFunctions</li>
                    </a>
                    <a href="https://juliagaussianprocesses.github.io/ApproximateGPs.jl/">
                        <li>ApproximateGPs</li>
                    </a>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading ext-navbar-item-single">
                        <a href="https://turinglang.org/Bijectors.jl/">Bijectors</a>
                    </li>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading ext-navbar-item-single">
                        <a href="https://turinglang.org/TuringCallbacks.jl/">TuringCallbacks</a>
                    </li>
                </ul>
                <ul>
                    <li class="ext-dropdown-item-heading ext-navbar-item-single">
                        <a href="https://turinglang.org/TuringBenchmarking.jl/">TuringBenchmarking</a>
                    </li>
                </ul>
            </div>
        </li> -->
    </ul>
    <a href="https://turinglang.org/" title="Co-developed with Turing.jl">
        <img src="https://turinglang.org/assets/images/turing-logo.svg" alt="Turing Logo" class="ext-navbar-logo turing-logo" height="24px" width="40px">
    </a>
    <!-- Github Logo -->
    <!-- <a href="https://github.com/JuliaGaussianProcesses/">
        <svg width="32px" height="32px" viewBox="-8.2 -8.2 36.40 36.40" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" fill="#000000">
            <g id="SVGRepo_bgCarrier" stroke-width="0"></g>
            <g id="SVGRepo_tracerCarrier" stroke-linecap="round" stroke-linejoin="round"></g>
            <g id="SVGRepo_iconCarrier">
                <title>github [#142]</title>
                <desc>Created with Sketch.</desc>
                <defs></defs>
                <g id="Page-1" stroke-width="0.0002" fill="none" fill-rule="evenodd">
                    <g id="Dribbble-Light-Preview" transform="translate(-140.000000, -7559.000000)" fill="#ffffff">
                        <g id="icons" transform="translate(56.000000, 160.000000)">
                            <path
                                d="M94,7399 C99.523,7399 104,7403.59 104,7409.253 C104,7413.782 101.138,7417.624 97.167,7418.981 C96.66,7419.082 96.48,7418.762 96.48,7418.489 C96.48,7418.151 96.492,7417.047 96.492,7415.675 C96.492,7414.719 96.172,7414.095 95.813,7413.777 C98.04,7413.523 100.38,7412.656 100.38,7408.718 C100.38,7407.598 99.992,7406.684 99.35,7405.966 C99.454,7405.707 99.797,7404.664 99.252,7403.252 C99.252,7403.252 98.414,7402.977 96.505,7404.303 C95.706,7404.076 94.85,7403.962 94,7403.958 C93.15,7403.962 92.295,7404.076 91.497,7404.303 C89.586,7402.977 88.746,7403.252 88.746,7403.252 C88.203,7404.664 88.546,7405.707 88.649,7405.966 C88.01,7406.684 87.619,7407.598 87.619,7408.718 C87.619,7412.646 89.954,7413.526 92.175,7413.785 C91.889,7414.041 91.63,7414.493 91.54,7415.156 C90.97,7415.418 89.522,7415.871 88.63,7414.304 C88.63,7414.304 88.101,7413.319 87.097,7413.247 C87.097,7413.247 86.122,7413.234 87.029,7413.87 C87.029,7413.87 87.684,7414.185 88.139,7415.37 C88.139,7415.37 88.726,7417.2 91.508,7416.58 C91.513,7417.437 91.522,7418.245 91.522,7418.489 C91.522,7418.76 91.338,7419.077 90.839,7418.982 C86.865,7417.627 84,7413.783 84,7409.253 C84,7403.59 88.478,7399 94,7399"
                                id="github-[#142]">
                            </path>
                        </g>
                    </g>
                </g>
            </g>
        </svg>
    </a> -->
    <span class="ext-menu-toggle">&#9776;</span>
</nav>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        const menuToggle = document.querySelector(".ext-menu-toggle");
        const navLinks = document.querySelector(".ext-nav-links");
        const nav = document.querySelector(".ext-navigation");
        const navigationHandler = document.getElementById("library-handler");
        const navigationItemsContainer =
            document.getElementById("ext-dropdown-items");
        let lastScrollY = window.scrollY;

        function setAppropriateHeight() {
            if (window.innerWidth <= 768) {
                const viewportHeight = window.innerHeight;
                const navHeight = nav.offsetHeight;
                navLinks.style.maxHeight = `${viewportHeight - navHeight}px`;
                navLinks.style.overflowY = "auto";
            } else {
                navLinks.style.maxHeight = "";
                navLinks.style.overflowY = "";
            }
        }

        // Toggle main menu for mobile
        menuToggle.addEventListener("click", () => {
            navLinks.classList.toggle("show");
            if (navLinks.classList.contains("show")) {
                setAppropriateHeight();
                // Ensure the dropdown is hidden when menu is first opened
                navigationItemsContainer.style.display = "none";
                navigationItemsContainer.classList.remove("show");
            }
        });

        // Close menus if clicked outside
        document.addEventListener("click", (event) => {
            if (
                !navLinks.contains(event.target) &&
                !menuToggle.contains(event.target)
            ) {
                navLinks.classList.remove("show");
                navigationItemsContainer.classList.remove("show");
                navigationHandler.classList.remove("open");
            }
        });

        // Hide navigation bar on scroll down in mobile view
        window.addEventListener("scroll", () => {
            if (window.innerWidth <= 768) {
                nav.classList.toggle("hide", window.scrollY > lastScrollY);
                lastScrollY = window.scrollY;
            }
        });

        // Library API script
        navigationHandler.addEventListener("click", (event) => {
            event.preventDefault(); // Prevent default action of the link
            if (navigationItemsContainer.classList.contains("show")) {
                navigationItemsContainer.classList.remove("show");
                navigationHandler.classList.remove("open");
                setTimeout(() => {
                    navigationItemsContainer.style.display = "none";
                }, 500); // Match the timeout to the CSS transition duration
            } else {
                navigationItemsContainer.style.display = "grid";
                navigationHandler.classList.add("open");
                setTimeout(() => {
                    navigationItemsContainer.classList.add("show");
                }, 10); // Delay to ensure the display change takes effect before adding class
            }
            setAppropriateHeight(); // Recalculate height when dropdown changes
        });

        // Handle window resize
        window.addEventListener("resize", setAppropriateHeight);

        // Initial setup
        setAppropriateHeight();
    });
</script>
<!-- NAVBAR END -->
    h::Kernel=SqExponentialKernel(),
    αs::AbstractVector{&lt;:Real},
    γs::AbstractMatrix{&lt;:Real},
    ωs::AbstractMatrix{&lt;:Real},
)</code></pre><p>where αs are the weights of dimension (A, ), γs is the covariance matrix of dimension (D, A) and ωs are the mean vectors and is of dimension (D, A). Here, D is input dimension and A is the number of spectral components.</p><p><code>h</code> is the kernel, which defaults to <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a> if not specified.</p><p>Generalised Spectral Mixture kernel function. This family of functions is  dense in the family of stationary real-valued kernels with respect to the pointwise convergence.[1]</p><p class="math-container">\[   κ(x, y) = αs&#39; (h(-(γs&#39; * t)^2) .* cos(π * ωs&#39; * t), t = x - y\]</p><p><strong>References:</strong></p><pre><code class="language-none">[1] Generalized Spectral Kernels, by Yves-Laurent Kom Samo and Stephen J. Roberts
[2] SM: Gaussian Process Kernels for Pattern Discovery and Extrapolation,
        ICML, 2013, by Andrew Gordon Wilson and Ryan Prescott Adams,
[3] Covariance kernels for fast automatic pattern discovery and extrapolation
    with Gaussian processes, Andrew Gordon Wilson, PhD Thesis, January 2014.
    http://www.cs.cmu.edu/~andrewgw/andrewgwthesis.pdf
[4] http://www.cs.cmu.edu/~andrewgw/pattern/.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/sm.jl#L1-L31">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.spectral_mixture_product_kernel" href="#KernelFunctions.spectral_mixture_product_kernel"><code>KernelFunctions.spectral_mixture_product_kernel</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">spectral_mixture_product_kernel(
    h::Kernel=SqExponentialKernel(),
    αs::AbstractMatrix{&lt;:Real},
    γs::AbstractMatrix{&lt;:Real},
    ωs::AbstractMatrix{&lt;:Real},
)</code></pre><p>where αs are the weights of dimension (D, A), γs is the covariance matrix of dimension (D, A) and ωs are the mean vectors and is of dimension (D, A). Here, D is input dimension and A is the number of spectral components.</p><p>Spectral Mixture Product Kernel. With enough components A, the SMP kernel can model any product kernel to arbitrary precision, and is flexible even with a small number of components [1]</p><p><code>h</code> is the kernel, which defaults to <a href="#KernelFunctions.SqExponentialKernel"><code>SqExponentialKernel</code></a> if not specified.</p><p class="math-container">\[   κ(x, y) = Πᵢ₌₁ᴷ Σ(αsᵢᵀ .* (h(-(γsᵢᵀ * tᵢ)²) .* cos(ωsᵢᵀ * tᵢ))), tᵢ = xᵢ - yᵢ\]</p><p><strong>References:</strong></p><pre><code class="language-none">[1] GPatt: Fast Multidimensional Pattern Extrapolation with GPs,
    arXiv 1310.5288, 2013, by Andrew Gordon Wilson, Elad Gilboa,
    Arye Nehorai and John P. Cunningham</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/sm.jl#L60-L87">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.PeriodicKernel" href="#KernelFunctions.PeriodicKernel"><code>KernelFunctions.PeriodicKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">PeriodicKernel(r::AbstractVector)
PeriodicKernel(dims::Int)
PeriodicKernel(T::DataType, dims::Int)</code></pre><p>Periodic Kernel as described in http://www.inference.org.uk/mackay/gpB.pdf eq. 47.</p><pre><code class="language-none">    κ(x,y) = exp( - 0.5 sum_i(sin (π(x_i - y_i))/r_i))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/periodic.jl#L1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.WienerKernel" href="#KernelFunctions.WienerKernel"><code>KernelFunctions.WienerKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">WienerKernel{i}()</code></pre><p>i-times integrated Wiener process kernel function.</p><ul><li>For i=-1, this is just the white noise covariance, see <a href="#KernelFunctions.WhiteKernel"><code>WhiteKernel</code></a>.</li><li>For i= 0, this is the Wiener process covariance,</li><li>For i= 1, this is the integrated Wiener process covariance (velocity),</li><li>For i= 2, this is the twice-integrated Wiener process covariance (accel.),</li><li>For i= 3, this is the thrice-integrated Wiener process covariance,</li></ul><p>where <span>$κᵢ$</span> is given by</p><p class="math-container">\[    κ₋₁(x, y) =  δ(x, y)
    κ₀(x, y)  =  min(x, y)\]</p><p>and for <span>$i &gt;= 1$</span>,</p><p class="math-container">\[    κᵢ(x, y) = 1 / aᵢ * min(x, y)^(2i + 1) + bᵢ * min(x, y)^(i + 1) * |x - y| * rᵢ(x, y),\]</p><pre><code class="language-none">with the coefficients ``aᵢ``, ``bᵢ`` and the residual ``rᵢ(x, y)`` defined as follows:</code></pre><p class="math-container">\[    a₁ = 3, b₁ = 1/2, r₁(x, y) = 1,
    a₂ = 20, b₂ = 1/12, r₂(x, y) = x + y - min(x, y) / 2,
    a₃ = 252, b₃ = 1/720, r₃(x, y) = 5 * max(x, y)² + 2 * x * z + 3 * min(x, y)²
\]</p><p><strong>References:</strong></p><p>See the paper <em>Probabilistic ODE Solvers with Runge-Kutta Means</em> by Schober, Duvenaud and Hennig, NIPS, 2014, for more details.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/basekernels/wiener.jl#L1-L34">source</a></section></article><h2 id="Composite-Kernels"><a class="docs-heading-anchor" href="#Composite-Kernels">Composite Kernels</a><a id="Composite-Kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Composite-Kernels" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.TransformedKernel" href="#KernelFunctions.TransformedKernel"><code>KernelFunctions.TransformedKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">TransformedKernel(k::Kernel,t::Transform)</code></pre><p>Return a kernel where inputs are pretransformed by <code>t</code> : <code>k(t(x),t(x&#39;))</code> Can also be called via <a href="#KernelFunctions.transform"><code>transform</code></a> : <code>transform(k, t)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/kernels/transformedkernel.jl#L1-L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ScaledKernel" href="#KernelFunctions.ScaledKernel"><code>KernelFunctions.ScaledKernel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ScaledKernel(k::Kernel, σ²::Real)</code></pre><p>Return a kernel premultiplied by the variance <code>σ²</code> : <code>σ² k(x,x&#39;)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/kernels/scaledkernel.jl#L1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.KernelSum" href="#KernelFunctions.KernelSum"><code>KernelFunctions.KernelSum</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">KernelSum &lt;: Kernel</code></pre><p>Create a sum of kernels. One can also use the operator <code>+</code>.</p><p>There are various ways in which you create a <code>KernelSum</code>:</p><p>The simplest way to specify a <code>KernelSum</code> would be to use the overloaded <code>+</code> operator. This is  equivalent to creating a <code>KernelSum</code> by specifying the kernels as the arguments to the constructor.  </p><pre><code class="language-julia-repl">julia&gt; k1 = SqExponentialKernel(); k2 = LinearKernel(); X = rand(5);

julia&gt; (k = k1 + k2) == KernelSum(k1, k2)
true

julia&gt; kernelmatrix(k1 + k2, X) == kernelmatrix(k1, X) .+ kernelmatrix(k2, X)
true

julia&gt; kernelmatrix(k, X) == kernelmatrix(k1 + k2, X)
true</code></pre><p>You could also specify a <code>KernelSum</code> by providing a <code>Tuple</code> or a <code>Vector</code> of the  kernels to be summed. We suggest you to use a <code>Tuple</code> when you have fewer components   and a <code>Vector</code> when dealing with a large number of components.</p><pre><code class="language-julia-repl">julia&gt; KernelSum((k1, k2)) == k1 + k2
true

julia&gt; KernelSum([k1, k2]) == KernelSum((k1, k2)) == k1 + k2
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/kernels/kernelsum.jl#L1-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.KernelProduct" href="#KernelFunctions.KernelProduct"><code>KernelFunctions.KernelProduct</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">KernelProduct &lt;: Kernel</code></pre><p>Create a product of kernels. One can also use the overloaded operator <code>*</code>.</p><p>There are various ways in which you create a <code>KernelProduct</code>:</p><p>The simplest way to specify a <code>KernelProduct</code> would be to use the overloaded <code>*</code> operator. This is  equivalent to creating a <code>KernelProduct</code> by specifying the kernels as the arguments to the constructor.  </p><pre><code class="language-julia-repl">julia&gt; k1 = SqExponentialKernel(); k2 = LinearKernel(); X = rand(5);

julia&gt; (k = k1 * k2) == KernelProduct(k1, k2)
true

julia&gt; kernelmatrix(k1 * k2, X) == kernelmatrix(k1, X) .* kernelmatrix(k2, X)
true

julia&gt; kernelmatrix(k, X) == kernelmatrix(k1 * k2, X)
true</code></pre><p>You could also specify a <code>KernelProduct</code> by providing a <code>Tuple</code> or a <code>Vector</code> of the  kernels to be multiplied. We suggest you to use a <code>Tuple</code> when you have fewer components   and a <code>Vector</code> when dealing with a large number of components.</p><pre><code class="language-julia-repl">julia&gt; KernelProduct((k1, k2)) == k1 * k2
true

julia&gt; KernelProduct([k1, k2]) == KernelProduct((k1, k2)) == k1 * k2
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/kernels/kernelproduct.jl#L1-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.TensorProduct" href="#KernelFunctions.TensorProduct"><code>KernelFunctions.TensorProduct</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">TensorProduct(kernels...)</code></pre><p>Create a tensor product kernel from kernels <span>$k_1, \ldots, k_n$</span>, i.e., a kernel <span>$k$</span> that is given by</p><p class="math-container">\[k(x, y) = \prod_{i=1}^n k_i(x_i, y_i).\]</p><p>The <code>kernels</code> can be specified as individual arguments, a tuple, or an iterable data structure such as an array. Using a tuple or individual arguments guarantees that <code>TensorProduct</code> is concretely typed but might lead to large compilation times if the number of kernels is large.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/kernels/tensorproduct.jl#L1-L14">source</a></section></article><h2 id="Transforms"><a class="docs-heading-anchor" href="#Transforms">Transforms</a><a id="Transforms-1"></a><a class="docs-heading-anchor-permalink" href="#Transforms" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.Transform" href="#KernelFunctions.Transform"><code>KernelFunctions.Transform</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Abstract type defining a slice-wise transformation on an input matrix</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/transform/transform.jl#L1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.IdentityTransform" href="#KernelFunctions.IdentityTransform"><code>KernelFunctions.IdentityTransform</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">IdentityTransform()</code></pre><p>Return exactly the input</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/transform/transform.jl#L9-L13">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ScaleTransform" href="#KernelFunctions.ScaleTransform"><code>KernelFunctions.ScaleTransform</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ScaleTransform(l::Real)</code></pre><p>Multiply every element of the input by <code>l</code></p><pre><code class="language-none">    l = 2.0
    tr = ScaleTransform(l)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/transform/scaletransform.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ARDTransform" href="#KernelFunctions.ARDTransform"><code>KernelFunctions.ARDTransform</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ARDTransform(v::AbstractVector)
ARDTransform(s::Real, dims::Int)</code></pre><p>Multiply every vector of observation by <code>v</code> element-wise</p><pre><code class="language-none">    v = rand(3)
    tr = ARDTransform(v)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/transform/ardtransform.jl#L1-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.LinearTransform" href="#KernelFunctions.LinearTransform"><code>KernelFunctions.LinearTransform</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LinearTransform(A::AbstractMatrix)</code></pre><p>Apply the linear transformation realised by the matrix <code>A</code>.</p><p>The second dimension of <code>A</code> must match the number of features of the target.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; A = rand(10, 5)
julia&gt; tr = LinearTransform(A)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/transform/lineartransform.jl#L1-L14">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.FunctionTransform" href="#KernelFunctions.FunctionTransform"><code>KernelFunctions.FunctionTransform</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">FunctionTransform(f)</code></pre><p>Take a function or object <code>f</code> as an argument which is going to act on each vector individually. Make sure that <code>f</code> is supposed to act on a vector. For example replace <code>f(x)=sin(x)</code> by <code>f(x)=sin.(x)</code></p><pre><code class="language-none">    f(x) = abs.(x)
    tr = FunctionTransform(f)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/transform/functiontransform.jl#L1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.SelectTransform" href="#KernelFunctions.SelectTransform"><code>KernelFunctions.SelectTransform</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">SelectTransform(dims)</code></pre><p>Select the dimensions <code>dims</code> that the kernel is applied to.</p><pre><code class="language-none">    dims = [1,3,5,6,7]
    tr = SelectTransform(dims)
    X = rand(100,10)
    transform(tr,X,obsdim=2) == X[dims,:]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/transform/selecttransform.jl#L1-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ChainTransform" href="#KernelFunctions.ChainTransform"><code>KernelFunctions.ChainTransform</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ChainTransform(ts::AbstractVector{&lt;:Transform})</code></pre><p>Chain a series of transform, here <code>t1</code> will be called first</p><pre><code class="language-none">    t1 = ScaleTransform()
    t2 = LinearTransform(rand(3,4))
    ct = ChainTransform([t1,t2]) #t1 will be called first
    ct == t2 ∘ t1</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/transform/chaintransform.jl#L1-L11">source</a></section></article><h2 id="Functions"><a class="docs-heading-anchor" href="#Functions">Functions</a><a id="Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.kernelmatrix" href="#KernelFunctions.kernelmatrix"><code>KernelFunctions.kernelmatrix</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">kernelmatrix(κ::Kernel, X; obsdim::Int = 2)
kernelmatrix(κ::Kernel, X, Y; obsdim::Int = 2)</code></pre><p>Calculate the kernel matrix of <code>X</code> (and <code>Y</code>) with respect to kernel <code>κ</code>. <code>obsdim = 1</code> means the matrix <code>X</code> (and <code>Y</code>) has size #samples x #dimension <code>obsdim = 2</code> means the matrix <code>X</code> (and <code>Y</code>) has size #dimension x #samples</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/matrix/kernelmatrix.jl#L10-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.kernelmatrix!" href="#KernelFunctions.kernelmatrix!"><code>KernelFunctions.kernelmatrix!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">kernelmatrix!(K::AbstractMatrix, κ::Kernel, X; obsdim::Integer = 2)
kernelmatrix!(K::AbstractMatrix, κ::Kernel, X, Y; obsdim::Integer = 2)</code></pre><p>In-place version of <a href="#KernelFunctions.kernelmatrix"><code>kernelmatrix</code></a> where pre-allocated matrix <code>K</code> will be overwritten with the kernel matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/matrix/kernelmatrix.jl#L1-L7">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.kerneldiagmatrix" href="#KernelFunctions.kerneldiagmatrix"><code>KernelFunctions.kerneldiagmatrix</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">kerneldiagmatrix(κ::Kernel, X; obsdim::Int = 2)</code></pre><p>Calculate the diagonal matrix of <code>X</code> with respect to kernel <code>κ</code> <code>obsdim = 1</code> means the matrix <code>X</code> has size #samples x #dimension <code>obsdim = 2</code> means the matrix <code>X</code> has size #dimension x #samples</p><pre><code class="language-none">kerneldiagmatrix(κ::Kernel, X, Y; obsdim::Int = 2)</code></pre><p>Calculate the diagonal of <code>kernelmatrix(κ, X, Y; obsdim)</code> efficiently. Requires that <code>X</code> and <code>Y</code> are the same length.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/matrix/kernelmatrix.jl#L28-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.kerneldiagmatrix!" href="#KernelFunctions.kerneldiagmatrix!"><code>KernelFunctions.kerneldiagmatrix!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">kerneldiagmatrix!(K::AbstractVector, κ::Kernel, X; obsdim::Int = 2)
kerneldiagmatrix!(K::AbstractVector, κ::Kernel, X, Y; obsdim::Int = 2)</code></pre><p>In place version of <a href="#KernelFunctions.kerneldiagmatrix"><code>kerneldiagmatrix</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/matrix/kernelmatrix.jl#L20-L25">source</a></section></article><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>kernelpdmat</code>. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>kernelkronmat</code>. Check Documenter&#39;s build log for details.</p></div></div><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.nystrom" href="#KernelFunctions.nystrom"><code>KernelFunctions.nystrom</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">nystrom(k::Kernel, X::Matrix, S::Vector; obsdim::Int=defaultobs)</code></pre><p>Computes a factorization of Nystrom approximation of the square kernel matrix of data matrix <code>X</code> with respect to kernel <code>k</code>. Returns a <code>NystromFact</code> struct which stores a Nystrom factorization satisfying:</p><p class="math-container">\[\mathbf{K} \approx \mathbf{C}^{\intercal}\mathbf{W}\mathbf{C}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/approximations/nystrom.jl#L62-L71">source</a></section><section><div><pre><code class="language-none">nystrom(k::Kernel, X::Matrix, r::Real; obsdim::Int=defaultobs)</code></pre><p>Computes a factorization of Nystrom approximation of the square kernel matrix of data matrix <code>X</code> with respect to kernel <code>k</code> using a sample ratio of <code>r</code>. Returns a <code>NystromFact</code> struct which stores a Nystrom factorization satisfying:</p><p class="math-container">\[\mathbf{K} \approx \mathbf{C}^{\intercal}\mathbf{W}\mathbf{C}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/approximations/nystrom.jl#L78-L87">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.transform" href="#KernelFunctions.transform"><code>KernelFunctions.transform</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">    transform(k::Kernel, t::Transform) (1)
    transform(k::Kernel, ρ::Real) (2)
    transform(k::Kernel, ρ::AbstractVector) (3)</code></pre><p>(1) Create a TransformedKernel with transform <code>t</code> and kernel <code>k</code> (2) Same as (1) with a <code>ScaleTransform</code> with scale <code>ρ</code> (3) Same as (1) with an <code>ARDTransform</code> with scales <code>ρ</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/kernels/transformedkernel.jl#L34-L43">source</a></section></article><h2 id="Utilities"><a class="docs-heading-anchor" href="#Utilities">Utilities</a><a id="Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Utilities" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.ColVecs" href="#KernelFunctions.ColVecs"><code>KernelFunctions.ColVecs</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ColVecs(X::AbstractMatrix)</code></pre><p>A lightweight wrapper for an <code>AbstractMatrix</code> to make it behave like a vector of vectors. Each vector represents a column of the matrix</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/utils.jl#L23-L28">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.RowVecs" href="#KernelFunctions.RowVecs"><code>KernelFunctions.RowVecs</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">RowVecs(X::AbstractMatrix)</code></pre><p>A lightweight wrapper for an <code>AbstractMatrix</code> to make it behave like a vector of vectors. Each vector represents a row of the matrix</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/utils.jl#L60-L65">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="KernelFunctions.NystromFact" href="#KernelFunctions.NystromFact"><code>KernelFunctions.NystromFact</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">NystromFact</code></pre><p>Type for storing a Nystrom factorization. The factorization contains two fields: <code>W</code> and <code>C</code>, two matrices satisfying:</p><p class="math-container">\[\mathbf{K} \approx \mathbf{C}^{\intercal}\mathbf{W}\mathbf{C}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/KernelFunctions.jl/blob/b38033dc7e893dedd28a8327cd9d257e3c4c2dff/src/approximations/nystrom.jl#L43-L51">source</a></section></article><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#KernelFunctions.ARDTransform"><code>KernelFunctions.ARDTransform</code></a></li><li><a href="#KernelFunctions.ChainTransform"><code>KernelFunctions.ChainTransform</code></a></li><li><a href="#KernelFunctions.ColVecs"><code>KernelFunctions.ColVecs</code></a></li><li><a href="#KernelFunctions.ConstantKernel"><code>KernelFunctions.ConstantKernel</code></a></li><li><a href="#KernelFunctions.CosineKernel"><code>KernelFunctions.CosineKernel</code></a></li><li><a href="#KernelFunctions.ExponentialKernel"><code>KernelFunctions.ExponentialKernel</code></a></li><li><a href="#KernelFunctions.ExponentiatedKernel"><code>KernelFunctions.ExponentiatedKernel</code></a></li><li><a href="#KernelFunctions.EyeKernel"><code>KernelFunctions.EyeKernel</code></a></li><li><a href="#KernelFunctions.FBMKernel"><code>KernelFunctions.FBMKernel</code></a></li><li><a href="#KernelFunctions.FunctionTransform"><code>KernelFunctions.FunctionTransform</code></a></li><li><a href="#KernelFunctions.GaborKernel"><code>KernelFunctions.GaborKernel</code></a></li><li><a href="#KernelFunctions.GammaExponentialKernel"><code>KernelFunctions.GammaExponentialKernel</code></a></li><li><a href="#KernelFunctions.GammaRationalQuadraticKernel"><code>KernelFunctions.GammaRationalQuadraticKernel</code></a></li><li><a href="#KernelFunctions.IdentityTransform"><code>KernelFunctions.IdentityTransform</code></a></li><li><a href="#KernelFunctions.KernelProduct"><code>KernelFunctions.KernelProduct</code></a></li><li><a href="#KernelFunctions.KernelSum"><code>KernelFunctions.KernelSum</code></a></li><li><a href="#KernelFunctions.LinearKernel"><code>KernelFunctions.LinearKernel</code></a></li><li><a href="#KernelFunctions.LinearTransform"><code>KernelFunctions.LinearTransform</code></a></li><li><a href="#KernelFunctions.MahalanobisKernel"><code>KernelFunctions.MahalanobisKernel</code></a></li><li><a href="#KernelFunctions.Matern32Kernel"><code>KernelFunctions.Matern32Kernel</code></a></li><li><a href="#KernelFunctions.Matern52Kernel"><code>KernelFunctions.Matern52Kernel</code></a></li><li><a href="#KernelFunctions.MaternKernel"><code>KernelFunctions.MaternKernel</code></a></li><li><a href="#KernelFunctions.NeuralNetworkKernel"><code>KernelFunctions.NeuralNetworkKernel</code></a></li><li><a href="#KernelFunctions.NystromFact"><code>KernelFunctions.NystromFact</code></a></li><li><a href="#KernelFunctions.PeriodicKernel"><code>KernelFunctions.PeriodicKernel</code></a></li><li><a href="#KernelFunctions.PiecewisePolynomialKernel"><code>KernelFunctions.PiecewisePolynomialKernel</code></a></li><li><a href="#KernelFunctions.PolynomialKernel"><code>KernelFunctions.PolynomialKernel</code></a></li><li><a href="#KernelFunctions.RationalQuadraticKernel"><code>KernelFunctions.RationalQuadraticKernel</code></a></li><li><a href="#KernelFunctions.RowVecs"><code>KernelFunctions.RowVecs</code></a></li><li><a href="#KernelFunctions.ScaleTransform"><code>KernelFunctions.ScaleTransform</code></a></li><li><a href="#KernelFunctions.ScaledKernel"><code>KernelFunctions.ScaledKernel</code></a></li><li><a href="#KernelFunctions.SelectTransform"><code>KernelFunctions.SelectTransform</code></a></li><li><a href="#KernelFunctions.SqExponentialKernel"><code>KernelFunctions.SqExponentialKernel</code></a></li><li><a href="#KernelFunctions.TensorProduct"><code>KernelFunctions.TensorProduct</code></a></li><li><a href="#KernelFunctions.Transform"><code>KernelFunctions.Transform</code></a></li><li><a href="#KernelFunctions.TransformedKernel"><code>KernelFunctions.TransformedKernel</code></a></li><li><a href="#KernelFunctions.WhiteKernel"><code>KernelFunctions.WhiteKernel</code></a></li><li><a href="#KernelFunctions.WienerKernel"><code>KernelFunctions.WienerKernel</code></a></li><li><a href="#KernelFunctions.ZeroKernel"><code>KernelFunctions.ZeroKernel</code></a></li><li><a href="#KernelFunctions.kerneldiagmatrix"><code>KernelFunctions.kerneldiagmatrix</code></a></li><li><a href="#KernelFunctions.kerneldiagmatrix!"><code>KernelFunctions.kerneldiagmatrix!</code></a></li><li><a href="#KernelFunctions.kernelmatrix"><code>KernelFunctions.kernelmatrix</code></a></li><li><a href="#KernelFunctions.kernelmatrix!"><code>KernelFunctions.kernelmatrix!</code></a></li><li><a href="#KernelFunctions.nystrom"><code>KernelFunctions.nystrom</code></a></li><li><a href="#KernelFunctions.spectral_mixture_kernel"><code>KernelFunctions.spectral_mixture_kernel</code></a></li><li><a href="#KernelFunctions.spectral_mixture_product_kernel"><code>KernelFunctions.spectral_mixture_product_kernel</code></a></li><li><a href="#KernelFunctions.transform"><code>KernelFunctions.transform</code></a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../create_kernel/">« Custom Kernels</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Saturday 9 January 2021 20:48">Saturday 9 January 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

